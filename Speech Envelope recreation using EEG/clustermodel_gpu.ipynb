{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a321c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33993f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.stats import pearsonr\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e50858b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('train.pt')\n",
    "val_data = torch.load('val.pt')\n",
    "test_data = torch.load('test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8a1875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data):\n",
    "    eeg_list = []\n",
    "    stim_list = []\n",
    "    for eeg, stim in data:\n",
    "        eeg_list.append(eeg.float())           # (320, 64)\n",
    "        stim_list.append(stim.float())         # (320,)\n",
    "    eeg_tensor = torch.stack(eeg_list)         # (N, 320, 64)\n",
    "    stim_tensor = torch.stack(stim_list)       # (N, 320)\n",
    "    return eeg_tensor, stim_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9559da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_dataset(train_data)\n",
    "X_val, y_val = prepare_dataset(val_data)\n",
    "X_test, y_test = prepare_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151ab2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=320*64, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, z\n",
    "\n",
    "def cluster_with_autoencoder(eeg_data, k=5, latent_dim=32, epochs=50, device='cpu'):\n",
    "    \n",
    "\n",
    "    N, T, C = eeg_data.shape\n",
    "    data_flat = eeg_data.reshape(N, T * C)\n",
    "    data_tensor = data_flat.clone().detach().float()\n",
    "    loader = DataLoader(TensorDataset(data_tensor), batch_size=64, shuffle=True)\n",
    "\n",
    "    model = EEGAutoencoder(input_dim=T*C, latent_dim=latent_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # Train autoencoder\n",
    "    model.train()\n",
    "    print(\"Training Autoencoder...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for batch, in pbar:\n",
    "            batch = batch.to(device)\n",
    "            recon, _ = model(batch)\n",
    "            loss = loss_fn(recon, batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    # Get latent features\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        latent_all = model.encoder(data_tensor.to(device)).cpu().numpy()\n",
    "\n",
    "    # KMeans on latent space\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(latent_all)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    return labels, latent_all, model, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b197dc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|█████████████████████████████████████████████████████| 1428/1428 [02:14<00:00, 10.62it/s, Loss=46.1551]\n",
      "Epoch 2/20: 100%|█████████████████████████████████████████████████████| 1428/1428 [02:21<00:00, 10.11it/s, Loss=40.5675]\n",
      "Epoch 3/20: 100%|█████████████████████████████████████████████████████| 1428/1428 [02:19<00:00, 10.20it/s, Loss=30.0283]\n",
      "Epoch 4/20: 100%|█████████████████████████████████████████████████████| 1428/1428 [02:23<00:00,  9.94it/s, Loss=37.0205]\n",
      "Epoch 5/20: 100%|█████████████████████████████████████████████████████| 1428/1428 [02:30<00:00,  9.47it/s, Loss=69.9301]\n",
      "Epoch 6/20: 100%|█████████████████████████████████████████████████████| 1428/1428 [02:32<00:00,  9.39it/s, Loss=62.7077]\n",
      "Epoch 7/20: 100%|█████████████████████████████████████████████████████| 1428/1428 [02:19<00:00, 10.24it/s, Loss=49.8189]\n",
      "Epoch 8/20: 100%|█████████████████████████████████████████████████████| 1428/1428 [02:19<00:00, 10.24it/s, Loss=35.5080]\n",
      "Epoch 9/20: 100%|█████████████████████████████████████████████████████| 1428/1428 [02:23<00:00,  9.97it/s, Loss=41.6575]\n",
      "Epoch 10/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:32<00:00,  9.39it/s, Loss=46.4826]\n",
      "Epoch 11/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:33<00:00,  9.29it/s, Loss=63.5836]\n",
      "Epoch 12/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:33<00:00,  9.32it/s, Loss=52.3734]\n",
      "Epoch 13/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:34<00:00,  9.26it/s, Loss=38.6037]\n",
      "Epoch 14/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:35<00:00,  9.20it/s, Loss=29.7157]\n",
      "Epoch 15/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:31<00:00,  9.45it/s, Loss=97.9370]\n",
      "Epoch 16/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:33<00:00,  9.32it/s, Loss=34.1809]\n",
      "Epoch 17/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:32<00:00,  9.34it/s, Loss=54.4155]\n",
      "Epoch 18/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:33<00:00,  9.32it/s, Loss=24.4470]\n",
      "Epoch 19/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:29<00:00,  9.54it/s, Loss=29.2735]\n",
      "Epoch 20/20: 100%|████████████████████████████████████████████████████| 1428/1428 [02:31<00:00,  9.44it/s, Loss=37.7956]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "device = 'cpu' if torch.cpu.is_available() else 'cpu'\n",
    "\n",
    "cluster_labels, latent_embeddings, cluster_model, kmeans = cluster_with_autoencoder(X_train, k=k, latent_dim=32, epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "120f3548",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_eeg = [X_train[cluster_labels == i] for i in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1719972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67510, 320, 64])\n",
      "torch.Size([355, 320, 64])\n",
      "torch.Size([139, 320, 64])\n",
      "torch.Size([22371, 320, 64])\n",
      "torch.Size([1006, 320, 64])\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print(clustered_eeg[i].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "122cc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_y = [y_train[cluster_labels == i] for i in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b1113b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67510, 320])\n",
      "torch.Size([355, 320])\n",
      "torch.Size([139, 320])\n",
      "torch.Size([22371, 320])\n",
      "torch.Size([1006, 320])\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print(clustered_y[i].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "108e88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_flat = X_val.view(X_val.shape[0], -1).to(device)   # shape: (N_val, 320*64)\n",
    "X_test_flat = X_test.view(X_test.shape[0], -1).to(device)\n",
    "\n",
    "\n",
    "cluster_model.eval()\n",
    "with torch.no_grad():\n",
    "    latent_val = cluster_model.encoder(X_val_flat).cpu().numpy()   # shape: (N_val, latent_dim)\n",
    "    latent_test = cluster_model.encoder(X_test_flat).cpu().numpy() # shape: (N_test, latent_dim)\n",
    "\n",
    "    \n",
    "val_cluster_labels = kmeans.predict(latent_val)\n",
    "test_cluster_labels = kmeans.predict(latent_test)\n",
    "\n",
    "\n",
    "clustered_val_eeg = [X_val[val_cluster_labels == i] for i in range(k)]\n",
    "clustered_val_y   = [y_val[val_cluster_labels == i] for i in range(k)]\n",
    "\n",
    "clustered_test_eeg = [X_test[test_cluster_labels == i] for i in range(k)]\n",
    "clustered_test_y   = [y_test[test_cluster_labels == i] for i in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea7fd4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_corr(pred, target):\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    target = target.detach().cpu().numpy()\n",
    "    correlations = [pearsonr(p, t)[0] for p, t in zip(pred, target)]\n",
    "    return sum(correlations) / len(correlations)\n",
    "\n",
    "def cosine_sim(pred, target):\n",
    "    return F.cosine_similarity(pred, target, dim=1).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6f45563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PearsonCorrelationLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PearsonCorrelationLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # pred, target: (B, T)\n",
    "        pred = pred - pred.mean(dim=1, keepdim=True)\n",
    "        target = target - target.mean(dim=1, keepdim=True)\n",
    "\n",
    "        numerator = (pred * target).sum(dim=1)\n",
    "        denominator = torch.sqrt((pred ** 2).sum(dim=1) * (target ** 2).sum(dim=1) + 1e-8)\n",
    "        correlation = numerator / denominator\n",
    "\n",
    "        # Negative mean correlation to be minimized\n",
    "        return -correlation.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7442a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMExpert(nn.Module):\n",
    "    def __init__(self, input_dim=64, hidden_dim=64, num_layers=1, output_dim=320):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):  # x: (B, 320, 64)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # use last time step hidden state\n",
    "        return out  # (B, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a33e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = [LSTMExpert().to(device) for _ in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2578eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expert 1/5 | Epoch 1/20: 100%|████████████████████████████████████████| 2110/2110 [03:00<00:00, 11.69it/s, loss=-0.0829]\n",
      "Expert 1/5 | Epoch 2/20: 100%|████████████████████████████████████████| 2110/2110 [02:23<00:00, 14.74it/s, loss=-0.0169]\n",
      "Expert 1/5 | Epoch 3/20: 100%|████████████████████████████████████████| 2110/2110 [01:57<00:00, 17.90it/s, loss=-0.0212]\n",
      "Expert 1/5 | Epoch 4/20: 100%|████████████████████████████████████████| 2110/2110 [01:20<00:00, 26.15it/s, loss=-0.0376]\n",
      "Expert 1/5 | Epoch 5/20: 100%|███████████████████████████████████████| 2110/2110 [01:22<00:00, 25.47it/s, loss=-0.00791]\n",
      "Expert 1/5 | Epoch 6/20:  46%|███████████████████▎                      | 970/2110 [00:34<00:56, 20.19it/s, loss=-0.116]"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    train_loader = DataLoader(TensorDataset(clustered_eeg[i], clustered_y[i]), batch_size=32, shuffle=True)\n",
    "    model = experts[i]\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = PearsonCorrelationLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loop = tqdm(train_loader, desc=f\"Expert {i+1}/{k} | Epoch {epoch+1}/{epochs}\")\n",
    "        for x, y in loop:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update progress bar with current loss\n",
    "            loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9fa242",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, experts, combine_dim=320, output_dim=320):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleList(experts)\n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Conv1d(k, 16, kernel_size=3, padding=1),  # k experts’ outputs as channels\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 1, kernel_size=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):  # x: (B, 320, 64)\n",
    "        expert_outputs = [expert(x) for expert in self.experts]  # list of (B, 320)\n",
    "        expert_stack = torch.stack(expert_outputs, dim=1)  # (B, k, 320)\n",
    "\n",
    "        # Move expert_stack and combine_layer to CPU\n",
    "        expert_stack_cpu = expert_stack.cpu()\n",
    "        combine_layer_cpu = self.combine_layer.to(device)\n",
    "\n",
    "        out = combine_layer_cpu(expert_stack_cpu)  # Run combine_layer on CPU\n",
    "        return out.squeeze(1).to(x.device)  # Move output back to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = torch.cat(clustered_eeg, dim=0)\n",
    "y_all = torch.cat(clustered_y, dim=0)\n",
    "train_loader = DataLoader(TensorDataset(X_all, y_all), batch_size=32, shuffle=True)\n",
    "\n",
    "combiner_model = CombinedModel(experts).to(device)\n",
    "optimizer = torch.optim.Adam(combiner_model.parameters(), lr=1e-4)\n",
    "loss_fn = PearsonCorrelationLoss()\n",
    "\n",
    "print(\"Training Combiner Model...\")\n",
    "for epoch in range(epochs):\n",
    "    # Training Phase\n",
    "    combiner_model.train()\n",
    "    for expert in experts:\n",
    "        expert.train()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = combiner_model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    combiner_model.combine_layer = combiner_model.combine_layer.to(device)\n",
    "    # Validation Phase with cluster-specific experts\n",
    "    combiner_model.eval()\n",
    "    for expert in experts:\n",
    "        expert.eval()\n",
    "\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X_val)):\n",
    "            x = X_val[i].unsqueeze(0).to(device)  # (1, 320, 64)\n",
    "            y = y_val[i].unsqueeze(0).to(device)  # (1, 320)\n",
    "            cluster_id = val_cluster_labels[i]\n",
    "\n",
    "            expert_output = experts[cluster_id](x)  # (1, 320)\n",
    "\n",
    "            # Fill other expert outputs with zeros\n",
    "            dummy_outputs = [torch.zeros_like(expert_output) for _ in range(len(experts))]\n",
    "            dummy_outputs[cluster_id] = expert_output\n",
    "            expert_stack = torch.stack(dummy_outputs, dim=1).to(device)  # <-- Add .to(device)\n",
    "#             print(\"expert_stack device:\", expert_stack.device)\n",
    "#             print(\"combine_layer weights device:\", next(combiner_model.combine_layer.parameters()).device)\n",
    "            pred = combiner_model.combine_layer(expert_stack).squeeze(1)\n",
    "\n",
    "            val_preds.append(pred)\n",
    "            val_targets.append(y)\n",
    "\n",
    "    val_preds = torch.cat(val_preds, dim=0)       # (N_val, 320)\n",
    "    val_targets = torch.cat(val_targets, dim=0)   # (N_val, 320)\n",
    "\n",
    "    val_mse = F.mse_loss(val_preds, val_targets).item()\n",
    "    val_pearson = pearson_corr(val_preds, val_targets)\n",
    "    val_cosine = cosine_sim(val_preds, val_targets)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f} | \"\n",
    "          f\"Val MSE = {val_mse:.4f} | Pearson = {val_pearson:.4f} | Cosine = {val_cosine:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combiner_model.eval()\n",
    "for expert in experts:\n",
    "    expert.eval()\n",
    "\n",
    "test_preds = []\n",
    "test_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        x = X_test[i].unsqueeze(0).to(device)  # (1, 320, 64)\n",
    "        y = y_test[i].unsqueeze(0).to(device)  # (1, 320)\n",
    "        cluster_id = test_cluster_labels[i]\n",
    "\n",
    "        expert_output = experts[cluster_id](x)  # (1, 320)\n",
    "\n",
    "        # Fill other expert outputs with zeros\n",
    "        dummy_outputs = [torch.zeros_like(expert_output) for _ in range(len(experts))]\n",
    "        dummy_outputs[cluster_id] = expert_output\n",
    "        expert_stack = torch.stack(dummy_outputs, dim=1).to(device)  \n",
    "        pred = combiner_model.combine_layer(expert_stack).squeeze(1)\n",
    "\n",
    "        test_preds.append(pred)\n",
    "        test_targets.append(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a979765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = torch.cat(test_preds, dim=0)       \n",
    "test_targets = torch.cat(test_targets, dim=0)   \n",
    "\n",
    "test_mse = F.mse_loss(test_preds, test_targets).item()\n",
    "test_pearson = pearson_corr(test_preds, test_targets)\n",
    "test_cosine = cosine_sim(test_preds, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Val MSE = {test_mse:.4f} | Pearson = {test_pearson:.4f} | Cosine = {test_cosine:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose a test index to visualize\n",
    "test_index = 0  # Change this to visualize different samples\n",
    "\n",
    "# Get predicted and true envelope\n",
    "pred_envelope = test_preds[test_index].cpu().numpy()\n",
    "true_envelope = test_targets[test_index].cpu().numpy()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(true_envelope, label='True Envelope', linewidth=2)\n",
    "plt.plot(pred_envelope, label='Predicted Envelope')\n",
    "plt.title(f\"Envelope Reconstruction (Test Sample {test_index})\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c02255",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):  # plot first 3 test samples\n",
    "    pred = test_preds[i].cpu().numpy()\n",
    "    true = test_targets[i].cpu().numpy()\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(true, label=\"True Envelope\")\n",
    "    plt.plot(pred, label=\"Predicted Envelope\")\n",
    "    plt.title(f\"Sample {i}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ae75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mtech_env)",
   "language": "python",
   "name": "mtech_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
