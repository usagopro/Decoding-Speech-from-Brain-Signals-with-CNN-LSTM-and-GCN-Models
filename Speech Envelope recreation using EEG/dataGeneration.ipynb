{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b61301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f222d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudiobookEEGDataset(Dataset):\n",
    "    def __init__(self, eeg_root, stim_root):\n",
    "        self.data_pairs = []\n",
    "\n",
    "        audiobook_pattern = re.compile(r'audiobook_\\d+_\\d+')\n",
    "        audiobook_pattern1 = re.compile(r'audiobook_\\d+')\n",
    "        podcast_pattern = re.compile(r'podcast_\\d+')\n",
    "\n",
    "        for subject in sorted(os.listdir(eeg_root)):\n",
    "            if subject.endswith(\".json\"):\n",
    "                continue\n",
    "            ses_path = os.path.join(eeg_root, subject)\n",
    "            subject_path = os.path.join(ses_path, os.listdir(ses_path)[0])\n",
    "            \n",
    "\n",
    "            for file in sorted(os.listdir(subject_path)):\n",
    "                if file.endswith(\".npy\"):\n",
    "                    eeg_path = os.path.join(subject_path, file)\n",
    "\n",
    "                    match = audiobook_pattern.search(file)\n",
    "                    if not match:\n",
    "                        match = audiobook_pattern1.search(file)\n",
    "                        if not match:\n",
    "                            match = podcast_pattern.search(file)\n",
    "                            if not match:\n",
    "                                print(f\"Warning: No audiobook ID found in {file}\")\n",
    "                                continue\n",
    "                        \n",
    "\n",
    "                    audiobook_id = match.group()\n",
    "                    stim_file = f\"{audiobook_id}_envelope.npy\"\n",
    "                    # print(stim_file)\n",
    "                    stim_path = os.path.join(stim_root, stim_file)\n",
    "\n",
    "                    if os.path.exists(stim_path):\n",
    "                        self.data_pairs.append((eeg_path, stim_path))\n",
    "                    else:\n",
    "                        stim_file = f\"{audiobook_id}_shifted_envelope.npy\"\n",
    "                        # print(stim_file)\n",
    "                        stim_path = os.path.join(stim_root, stim_file)\n",
    "                        if os.path.exists(stim_path):\n",
    "                            self.data_pairs.append((eeg_path, stim_path))\n",
    "                        else:\n",
    "                            print(f\"Warning: Stimulus file not found for {file}\")\n",
    "\n",
    "        print(f\"Loaded {len(self.data_pairs)} EEG-stimulus pairs\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg_path, stim_path = self.data_pairs[idx]\n",
    "\n",
    "        eeg = np.load(eeg_path)  # shape: (64, T)\n",
    "        stim = np.load(stim_path)  # shape: (T, 1)\n",
    "\n",
    "        # Transpose EEG to (T, 64) if needed\n",
    "        if eeg.shape[0] == 64:\n",
    "            eeg = eeg.T  # shape becomes (T, 64)\n",
    "\n",
    "        # Flatten stimulus if needed\n",
    "        stim = stim.squeeze()  # shape becomes (T,)\n",
    "\n",
    "        # Align lengths by trimming to shortest length\n",
    "        min_len = min(eeg.shape[0], stim.shape[0])\n",
    "        eeg = eeg[:min_len]\n",
    "        stim = stim[:min_len]\n",
    "        # print(eeg.shape[0], stim.shape[0])\n",
    "\n",
    "        eeg_tensor = torch.tensor(eeg, dtype=torch.float32)\n",
    "        stim_tensor = torch.tensor(stim, dtype=torch.float32)\n",
    "\n",
    "        return [eeg_tensor, stim_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a4fde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 588 EEG-stimulus pairs\n"
     ]
    }
   ],
   "source": [
    "eeg_root = '../data/derivatives/preprocessed_eeg'\n",
    "stim_root = '../data/derivatives/preprocessed_stimuli'\n",
    "\n",
    "dataset = AudiobookEEGDataset(eeg_root, stim_root)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a0ffd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_trials(d):\n",
    "    data = []\n",
    "    window_length = 5 * 64       # 320\n",
    "    overlap = 1 * 64             # 64\n",
    "    stride = window_length - overlap  # 256\n",
    "\n",
    "    for eeg, stim in d:\n",
    "        assert eeg.shape[0] == stim.shape[0], \"EEG and stim must be same length\"\n",
    "        T = eeg.shape[0]\n",
    "\n",
    "        cur = 0\n",
    "        while cur + window_length <= T:\n",
    "            eeg_seg = eeg[cur:cur + window_length]   # (320, 64)\n",
    "            stim_seg = stim[cur:cur + window_length] # (320,)\n",
    "            data.append((eeg_seg, stim_seg))\n",
    "            cur += stride\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "890b2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1749a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = segment_trials(train)\n",
    "val_data = segment_trials(val)\n",
    "test_data = segment_trials(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29d43302",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data, 'train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71f7a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_data, 'test.pt')\n",
    "torch.save(val_data, 'val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa815193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
