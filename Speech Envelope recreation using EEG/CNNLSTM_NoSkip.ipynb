{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9d9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.stats import pearsonr\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c03d6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = torch.load('train.pt')\n",
    "val_data = torch.load('val.pt')\n",
    "test_data = torch.load('test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f57735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "def prepare_dataset(data):\n",
    "    eeg_list = []\n",
    "    stim_list = []\n",
    "    for eeg, stim in data:\n",
    "        eeg_list.append(eeg.float())           # (320, 64)\n",
    "        stim_list.append(stim.float())         # (320,)\n",
    "    eeg_tensor = torch.stack(eeg_list)         # (N, 320, 64)\n",
    "    stim_tensor = torch.stack(stim_list)       # (N, 320)\n",
    "    return eeg_tensor, stim_tensor\n",
    "\n",
    "X_train, y_train = prepare_dataset(train_data)\n",
    "X_val, y_val = prepare_dataset(val_data)\n",
    "X_test, y_test = prepare_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a8782d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson Correlation Loss\n",
    "class PearsonCorrelationLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PearsonCorrelationLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred - pred.mean(dim=1, keepdim=True)\n",
    "        target = target - target.mean(dim=1, keepdim=True)\n",
    "\n",
    "        numerator = (pred * target).sum(dim=1)\n",
    "        denominator = torch.sqrt((pred ** 2).sum(dim=1) * (target ** 2).sum(dim=1) + 1e-8)\n",
    "\n",
    "        correlation = numerator / denominator\n",
    "        return -correlation.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbac381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model without skip connection\n",
    "class CNNLSTMNoSkip(nn.Module):\n",
    "    def __init__(self, in_channels=64, lstm_hidden_dim=64):\n",
    "        super(CNNLSTMNoSkip, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=lstm_hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=2 * lstm_hidden_dim, hidden_size=lstm_hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.regressor = nn.Linear(2 * lstm_hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)          # (B, 64, 320)\n",
    "        x = self.cnn(x)                 # (B, 64, 320)\n",
    "        x = x.permute(0, 2, 1)          # (B, 320, 64)\n",
    "        x, _ = self.lstm1(x)            # (B, 320, 2*H)\n",
    "        x, _ = self.lstm2(x)            # (B, 320, 2*H)\n",
    "        x = self.regressor(x)          # (B, 320, 1)\n",
    "        x = x.squeeze(-1)              # (B, 320)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1938c710",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNNLSTMWithSkip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCNNLSTMWithSkip\u001b[49m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m PearsonCorrelationLoss()\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CNNLSTMWithSkip' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993430bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mtech_env)",
   "language": "python",
   "name": "mtech_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
